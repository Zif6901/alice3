<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ALICE Voice Agent</title>

  <script>
    try {
      localStorage.removeItem('df-messenger-state');
      localStorage.removeItem('df-messenger-settings');
    } catch(e) {}
  </script>

  <link rel="stylesheet" href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">
  <style>
    /* Widget Styling */
    df-messenger {
      z-index: 999;
      position: fixed;
      --df-messenger-font-color: #000;
      --df-messenger-font-family: Google Sans;
      --df-messenger-chat-background: #f3f6fc;
      --df-messenger-message-user-background: #d3e3fd;
      --df-messenger-message-bot-background: #fff;
      
      /* Force Large Size */
      --df-messenger-chat-window-height: 80vh !important; 
      --df-messenger-chat-window-width: 500px !important; 
      
      bottom: 16px;
      right: 16px;
    }

    /* Microphone Button */
    #voice-trigger-btn {
      position: fixed; bottom: 20px; right: 90px; z-index: 1000;
      width: 50px; height: 50px; border-radius: 50%; border: none;
      background-color: #4285F4; color: white; font-size: 24px; cursor: pointer;
      box-shadow: 0 4px 8px rgba(0,0,0,0.2); display: flex; align-items: center;
      justify-content: center; transition: background-color 0.2s ease, transform 0.2s ease;
      outline: none;
    }
    #voice-trigger-btn:hover { transform: scale(1.1); }
    
    /* STATES */
    /* Initializing: Solid Yellow (Wait) */
    #voice-trigger-btn.initializing { background-color: #FBBC05 !important; cursor: wait; }
    
    /* Hearing: Flashing Red (Speak Now) */
    #voice-trigger-btn.hearing { background-color: #EA4335 !important; box-shadow: 0 0 15px #EA4335; animation: pulse-red 1.5s infinite; }
    
    /* Speaking: Flashing Yellow (Alice Talking) */
    #voice-trigger-btn.speaking { background-color: #FBBC05 !important; color: #fff; cursor: pointer; animation: pulse-ring-yellow 1.5s infinite; }

    #mute-btn {
      position: fixed; bottom: 25px; right: 150px; z-index: 1000; width: 40px; height: 40px;
      border-radius: 50%; border: none; background-color: #f1f3f4; color: #5f6368; font-size: 20px;
      cursor: pointer; box-shadow: 0 2px 6px rgba(0,0,0,0.2); display: flex; align-items: center;
      justify-content: center; transition: all 0.2s ease; outline: none;
    }
    #mute-btn:hover { background-color: #e8eaed; transform: scale(1.1); }
    #mute-btn.muted { background-color: #fce8e6; color: #d93025; }

    #live-transcript {
      position: fixed; bottom: 28px; right: 210px; background: rgba(32, 33, 36, 0.95);
      color: white; padding: 10px 16px; border-radius: 24px; font-family: 'Google Sans', sans-serif;
      font-size: 14px; letter-spacing: 0.5px; max-width: 400px; display: none; z-index: 998;
      box-shadow: 0 4px 12px rgba(0,0,0,0.15); white-space: nowrap; overflow: hidden;
      text-overflow: ellipsis; pointer-events: none; transition: opacity 0.3s ease;
    }
    
    @keyframes pulse-red { 0% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(234, 67, 53, 0); } 100% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0); } }
    @keyframes pulse-ring-yellow { 0% { box-shadow: 0 0 0 0 rgba(251, 188, 5, 0.7); } 70% { box-shadow: 0 0 0 15px rgba(251, 188, 5, 0); } 100% { box-shadow: 0 0 0 0 rgba(251, 188, 5, 0); } }
  </style>
</head>
<body>

  <script>
    // This loop runs every 50ms to hunt for the widget
    const nuclearOpenLoop = setInterval(() => {
        const dfMessenger = document.querySelector('df-messenger');
        if (dfMessenger && dfMessenger.shadowRoot) {
            const shadow = dfMessenger.shadowRoot;
            if (!shadow.querySelector('#nuclear-open-style')) {
                const style = document.createElement('style');
                style.id = 'nuclear-open-style';
                style.textContent = `
                    .chat-wrapper { 
                        display: flex !important;
                        visibility: visible !important;
                        opacity: 1 !important;
                        bottom: 0px !important;
                        height: var(--df-messenger-chat-window-height) !important;
                        width: var(--df-messenger-chat-window-width) !important;
                        transform: none !important;
                        pointer-events: all !important;
                    }
                `;
                shadow.appendChild(style);
            }
            if (dfMessenger.getAttribute('expand') !== 'true') {
                 dfMessenger.setAttribute('expand', 'true');
            }
            const wrapper = shadow.querySelector('.chat-wrapper');
            if (wrapper && window.getComputedStyle(wrapper).display !== 'none') {
                clearInterval(nuclearOpenLoop);
            }
        }
    }, 50);
    setTimeout(() => clearInterval(nuclearOpenLoop), 10000);
  </script>

  <script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
   
  <df-messenger
    expand="true"
    location="us"
    project-id="vz-nonit-np-k25v-dev-aliceg-0"
    agent-id="bc4d57c6-899b-4e4a-bc7b-9739ac8a60ed"
    language-code="en"
    max-query-length="-1">
    <df-messenger-chat-bubble
      chat-title="ALICE-Voice-v9"
      chat-title-icon="https://storage.cloud.google.com/alice-avatars/ALICE TT&I.png">
    </df-messenger-chat-bubble>
  </df-messenger>

  <div id="live-transcript">Initializing...</div>
  <button id="mute-btn" title="Toggle Sound Response">üîä</button>
  <button id="voice-trigger-btn" title="Click to Speak">üéôÔ∏è</button>

  <script>
    // --- APP LOGIC ---
    const micBtn = document.getElementById('voice-trigger-btn');
    const muteBtn = document.getElementById('mute-btn');
    const transcriptBox = document.getElementById('live-transcript');
    const dfMessenger = document.querySelector('df-messenger');

    const EXIT_COMMANDS = ["stop", "thank you", "thanks", "bye", "cancel"];
    const STABILITY_DELAY = 1200; 
    
    let isMicActive = false;
    let isProcessing = false; 
    let isMuted = false;
    let availableVoices = [];
    
    let debounceTimer = null; 
    let watchdogTimer = null; // Stored ID so we can cancel it
    let pendingTranscript = ""; 

    // --- LOAD VOICES ---
    const loadVoices = () => { availableVoices = window.speechSynthesis.getVoices(); };
    window.speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices();

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.continuous = false;  
      recognition.interimResults = true; 
      recognition.lang = 'en-US';

      // --- BUTTON CLICK ---
      micBtn.addEventListener('click', () => {
        // 1. INTERRUPT: If Alice is speaking (Processing), STOP her and Listen.
        if (isProcessing) {
            console.log("üëÜ User Interrupted Audio -> Switching to Listen");
            window.speechSynthesis.cancel();
            isProcessing = false;
            startMic(); // Immediate Red
            return;
        }

        // 2. TOGGLE: Normal on/off
        if (isMicActive) {
            manualStop(); 
        } else {
            startMic();
        }
      });

      function startMic() {
          if (isMicActive) return;

          // Clear any lingering watchdogs
          clearTimeout(watchdogTimer);

          pendingTranscript = "";
          transcriptBox.style.display = "block";
          transcriptBox.innerText = "Listening...";
          
          // Visual: Immediate Red
          updateButtonState("hearing"); 
          
          try { 
             recognition.start(); 
             isMicActive = true;
          } catch(e) {
             if(e.message && e.message.includes('started')) {
                 isMicActive = true;
             }
          }
      }

      recognition.onstart = () => { 
          isMicActive = true;
          transcriptBox.innerText = "Listening...";
          updateButtonState("hearing"); 
      };

      function manualStop() {
          isMicActive = false;
          recognition.stop();
          if (pendingTranscript.length > 1) {
              executeCommand(pendingTranscript);
          } else {
              transcriptBox.style.display = "none";
              updateButtonState("idle");
          }
      }

      // --- CORE LOGIC ---
      recognition.onresult = (event) => {
        const results = event.results;
        const latestResult = results[results.length - 1];
        let transcript = latestResult[0].transcript;
        
        let command = transcript.replace(/^[^a-zA-Z0-9]+/, '').trim();
        if (command.length < 1) return;

        pendingTranscript = command; 

        const time = new Date().toLocaleTimeString().split(' ')[0];
        transcriptBox.innerText = `[${time}] Heard: "${command}"...`;

        clearTimeout(debounceTimer);

        if (latestResult.isFinal) {
            console.log("üöÄ Final Result detected. Sending.");
            recognition.stop(); 
        } else {
            debounceTimer = setTimeout(() => {
                console.log("‚è∞ Silence Timer detected. Sending.");
                recognition.stop(); 
            }, STABILITY_DELAY);
        }
      };

      recognition.onend = () => {
          isMicActive = false;
          
          if (pendingTranscript.length > 1) {
              if (EXIT_COMMANDS.includes(pendingTranscript.toLowerCase())) {
                  transcriptBox.innerText = "Session Ended.";
                  updateButtonState("idle");
                  return;
              }
              executeCommand(pendingTranscript);
          } else {
              // Only go blue if we aren't already processing an answer
              if (!isProcessing) updateButtonState("idle");
          }
      };

      recognition.onerror = (event) => {
          if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
              updateButtonState("idle");
              isMicActive = false;
          }
      };

      function executeCommand(text) {
          isProcessing = true; 
          
          // IMMEDIATE YELLOW (Waiting/Speaking)
          updateButtonState("speaking");
          
          transcriptBox.innerText = `Sent: "${text}"`;
          console.log("SENDING:", text);
          
          // Watchdog: If Dialogflow is dead for 8 seconds, reset.
          clearTimeout(watchdogTimer);
          watchdogTimer = setTimeout(() => {
              if (isProcessing) {
                 console.warn("Watchdog: No response.");
                 isProcessing = false;
                 updateButtonState("idle");
              }
          }, 8000);
          
          dfMessenger.setAttribute('expand', 'true');
          dfMessenger.renderCustomText(text, true);
          dfMessenger.sendRequest("query", text);
          
          pendingTranscript = ""; 
      }

    } else {
        alert("Browser not supported");
    }

    function updateButtonState(state) {
        micBtn.classList.remove('initializing', 'hearing', 'speaking');
        micBtn.style.backgroundColor = "#4285F4"; // Blue by default
        
        if (state === "initializing") micBtn.classList.add('initializing');
        else if (state === "hearing") micBtn.classList.add('hearing');
        else if (state === "speaking") micBtn.classList.add('speaking');
    }

    // --- RESPONSE HANDLING ---
    window.addEventListener('df-response-received', (event) => {
        // 1. DATA RECEIVED: KILL THE WATCHDOG IMMEDIATELY
        // This stops the button from turning Blue if she talks for a long time.
        clearTimeout(watchdogTimer);
        
        let botText = "";
        if (event.detail.messages) {
            const msg = event.detail.messages.find(m => m.type === 'text');
            if (msg) botText = msg.text;
        }
        if (!botText && event.detail.raw && event.detail.raw.queryResult) {
            const qr = event.detail.raw.queryResult;
            if (qr.responseMessages) {
                const txt = qr.responseMessages.find(m => m.text);
                if (txt) botText = txt.text.text[0];
            } else if (qr.fulfillmentText) botText = qr.fulfillmentText;
        }

        if (botText && !isMuted) {
            transcriptBox.innerText = "Alice is speaking (Tap to Interrupt)...";
            // Reinforce Yellow
            updateButtonState("speaking");
            speakText(botText);
        } else {
            // If there's no text (e.g. just a card), loop back to Mic immediately.
            isProcessing = false;
            startMic(); 
        }

        if (event.detail.raw && event.detail.raw.queryResult) {
            const msgs = event.detail.raw.queryResult.responseMessages || event.detail.raw.queryResult.fulfillmentMessages;
            if (msgs) {
                const audioMsg = msgs.find(m => m.payload && m.payload.audioUrl);
                if (audioMsg && !isMuted) playAudioFile(audioMsg.payload.audioUrl);
            }
        }
    });

    function speakText(text) {
        window.speechSynthesis.cancel();
        const utterance = new SpeechSynthesisUtterance(text);
        if (availableVoices.length === 0) availableVoices = window.speechSynthesis.getVoices();
        let v = availableVoices.find(v => v.name.includes("Google") && v.name.includes("US"));
        if (!v) v = availableVoices.find(v => v.lang.includes("en-"));
        if (v) utterance.voice = v;
        
        // --- SEAMLESS TRANSITION ---
        // When she finishes speaking, switch immediately to Red (Listening).
        utterance.onend = () => { 
            isProcessing = false;
            startMic(); 
        };
        
        utterance.onerror = () => { 
            isProcessing = false;
            startMic(); 
        };
        window.speechSynthesis.speak(utterance);
    }

    function playAudioFile(url) {
        updateButtonState("speaking");
        const audio = new Audio(url);
        audio.onended = () => {
             isProcessing = false;
             startMic(); 
        };
        audio.onerror = () => {
             isProcessing = false;
             startMic();
        };
        audio.play();
    }

    muteBtn.addEventListener('click', () => {
        isMuted = !isMuted;
        muteBtn.textContent = isMuted ? "üîá" : "üîä";
        muteBtn.classList.toggle('muted', isMuted);
        if (isMuted) window.speechSynthesis.cancel();
    });
  </script>
</body>
</html>




