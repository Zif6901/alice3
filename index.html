<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Alice Agent (Wake Word Enabled)</title>

  <link rel="stylesheet" href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">
  <style>
    /* --- Widget Styling --- */
    df-messenger {
      z-index: 999;
      position: fixed;
      --df-messenger-font-color: #000;
      --df-messenger-font-family: Google Sans;
      --df-messenger-chat-background: #f3f6fc;
      --df-messenger-message-user-background: #d3e3fd;
      --df-messenger-message-bot-background: #fff;
      bottom: 16px;
      right: 16px;
    }

    /* --- Microphone Button Styling --- */
    #voice-trigger-btn {
      position: fixed;
      bottom: 100px; 
      right: 24px;   
      z-index: 1000;
      width: 60px;
      height: 60px;
      border-radius: 50%;
      border: none;
      background-color: #4285F4; /* Default Google Blue */
      color: white;
      font-size: 28px;
      cursor: pointer;
      box-shadow: 0 4px 8px rgba(0,0,0,0.2);
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
      outline: none;
    }

    #voice-trigger-btn:hover {
      transform: scale(1.1);
      box-shadow: 0 6px 12px rgba(0,0,0,0.3);
    }

    /* STATE: Listening for Wake Word (Blue Pulse) */
    #voice-trigger-btn.listening {
      background-color: #4285F4; 
      animation: pulse-blue 2s infinite;
    }

    /* STATE: Processing/Active (Red Pulse) */
    #voice-trigger-btn.processing {
      background-color: #EA4335;
      animation: pulse-red 1.0s infinite;
    }

    /* --- Mute Button Styling --- */
    #mute-btn {
      position: fixed;
      bottom: 170px; 
      right: 34px;   
      z-index: 1000;
      width: 40px;   
      height: 40px;
      border-radius: 50%;
      border: none;
      background-color: #f1f3f4;
      color: #5f6368;
      font-size: 20px;
      cursor: pointer;
      box-shadow: 0 2px 6px rgba(0,0,0,0.2);
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.2s ease;
      outline: none;
    }

    #mute-btn:hover {
      background-color: #e8eaed;
      transform: scale(1.1);
    }
    
    #mute-btn.muted {
      background-color: #fce8e6;
      color: #d93025;
    }

    /* Animations */
    @keyframes pulse-blue {
      0% { box-shadow: 0 0 0 0 rgba(66, 133, 244, 0.7); }
      70% { box-shadow: 0 0 0 15px rgba(66, 133, 244, 0); }
      100% { box-shadow: 0 0 0 0 rgba(66, 133, 244, 0); }
    }

    @keyframes pulse-red {
      0% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.7); }
      70% { box-shadow: 0 0 0 10px rgba(234, 67, 53, 0); }
      100% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0); }
    }
  </style>
</head>
<body>

  <script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
   
  <df-messenger
    location="us"
    project-id="vz-nonit-np-k25v-dev-aliceg-0"
    agent-id="3adf7da3-c967-48ee-b295-9a67c9b090fe"
    language-code="en"
    max-query-length="-1">
    <df-messenger-chat-bubble
      chat-title="alice3-duplicate"
      chat-title-icon="https://storage.cloud.google.com/alice-avatars/ALICE TT&I.png">
    </df-messenger-chat-bubble>
  </df-messenger>

  <button id="mute-btn" title="Toggle Sound Response">üîä</button>
  <button id="voice-trigger-btn" title="Start/Stop Wake Word Detection">üéôÔ∏è</button>

  <script>
    const dfMessenger = document.querySelector('df-messenger');
    const micBtn = document.getElementById('voice-trigger-btn');
    const muteBtn = document.getElementById('mute-btn');
    let isMuted = false;

    // Force voices to load
    window.speechSynthesis.getVoices();

    // --- 1. SAFE RESPONSE HANDLING ---
    window.addEventListener('df-response-received', (event) => {
        console.log("‚úÖ Event Triggered");
        
        // 1. Inspect the ENTIRE detail object to find where data is hiding
        console.log("Full Event Detail:", event.detail);

        // 2. SAFETY CHECK: Find the correct data path
        let data = null;
        if (event.detail.response) {
            data = event.detail.response; // Standard Path
        } else if (event.detail.queryResult) {
            data = event.detail; // Alternative Path (Data is at top level)
        } else if (event.detail.data) {
            data = event.detail.data; // Alternative Path 2
        }

        // If we still can't find data, stop here to prevent crash
        if (!data) {
            console.error("‚ùå Could not find 'response' or 'queryResult' in event.detail");
            return;
        }

        // 3. Extract Text (Try both ES and CX structures on the found data)
        let botText = "";
        const queryResult = data.queryResult;

        if (queryResult) {
             if (queryResult.fulfillmentText) {
                // Dialogflow ES
                botText = queryResult.fulfillmentText;
                console.log("Mode: Dialogflow ES");
            } else if (queryResult.responseMessages) {
                // Dialogflow CX
                console.log("Mode: Dialogflow CX");
                const textMsg = queryResult.responseMessages.find(msg => msg.text);
                if (textMsg && textMsg.text.text.length > 0) {
                    botText = textMsg.text.text[0];
                }
            }
        }

        console.log("üó£Ô∏è Bot Text to Speak:", botText);

        // 4. Speak
        if (botText && !isMuted) {
            speakText(botText);
        }
    });

    function speakText(text) {
        window.speechSynthesis.cancel(); 
        const utterance = new SpeechSynthesisUtterance(text);
        window.speechSynthesis.speak(utterance);
    }

    // --- 2. MUTE BUTTON ---
    muteBtn.addEventListener('click', () => {
        isMuted = !isMuted;
        muteBtn.textContent = isMuted ? "üîá" : "üîä";
        muteBtn.classList.toggle('muted', isMuted);
        if (isMuted) window.speechSynthesis.cancel();
    });

    // --- 3. SPEECH RECOGNITION ---
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.lang = 'en-US';

      micBtn.addEventListener('click', () => {
          dfMessenger.setAttribute('expand', 'true');
          recognition.start();
          micBtn.style.backgroundColor = "red"; 
      });

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        console.log("User said:", transcript);
        dfMessenger.renderCustomText(transcript, true);
        dfMessenger.sendRequest("query", transcript);
      };

      recognition.onend = () => { 
          micBtn.style.backgroundColor = "#4285F4"; 
      };
    }
  </script>
</body>
</html>







