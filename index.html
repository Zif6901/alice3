<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Alice Agent (Voice Enabled)</title>

  <link rel="stylesheet" href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">
  <style>
    /* --- WIDGET STYLING --- */
    df-messenger {
      z-index: 999;
      position: fixed;
      --df-messenger-font-color: #000;
      --df-messenger-font-family: Google Sans;
      --df-messenger-chat-background: #f3f6fc;
      --df-messenger-message-user-background: #d3e3fd;
      --df-messenger-message-bot-background: #fff;
      bottom: 16px;
      right: 16px;
    }

    /* --- MICROPHONE BUTTON --- */
    #voice-trigger-btn {
      position: fixed;
      bottom: 100px; 
      right: 24px;   
      z-index: 1000;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      border: none;
      background-color: #4285F4;
      color: white;
      font-size: 24px;
      cursor: pointer;
      box-shadow: 0 4px 8px rgba(0,0,0,0.2);
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
      outline: none;
    }

    #voice-trigger-btn:hover {
      transform: scale(1.1);
      background-color: #3367D6;
    }

    #voice-trigger-btn.recording {
      background-color: #EA4335;
      animation: pulse-red 1.5s infinite;
    }

    @keyframes pulse-red {
      0% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.7); }
      70% { box-shadow: 0 0 0 10px rgba(234, 67, 53, 0); }
      100% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0); }
    }

    /* --- STATUS INDICATOR --- */
    #status-indicator {
      position: fixed;
      bottom: 160px;
      right: 24px;
      background-color: #333;
      color: white;
      padding: 8px 16px;
      border-radius: 20px;
      font-family: 'Google Sans', sans-serif;
      font-size: 14px;
      opacity: 0.9;
      z-index: 1000;
      pointer-events: none;
      display: none;
    }
  </style>
</head>
<body>

  <script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
   
  <df-messenger
    location="us"
    project-id="vz-nonit-np-k25v-dev-aliceg-0"
    agent-id="3adf7da3-c967-48ee-b295-9a67c9b090fe"
    language-code="en"
    max-query-length="-1">
    <df-messenger-chat-bubble
      chat-title="alice3-duplicate"
      chat-title-icon="https://storage.cloud.google.com/alice-avatars/ALICE TT&I.png">
    </df-messenger-chat-bubble>
  </df-messenger>

  <div id="status-indicator">Ready</div>
  <button id="voice-trigger-btn">üéôÔ∏è</button>

  <script>
    // Wait for the Dialogflow Widget to be totally ready
    window.addEventListener('df-messenger-loaded', () => {
        console.log("Dialogflow Messenger loaded and ready.");
        initializeVoiceInterface();
    });

    // Fallback: If event doesn't fire quickly (sometimes happens in cache), init anyway after 1s
    setTimeout(() => {
        if (!window.voiceInterfaceInitialized) initializeVoiceInterface();
    }, 1000);

    function initializeVoiceInterface() {
        if (window.voiceInterfaceInitialized) return;
        window.voiceInterfaceInitialized = true;

        const dfMessenger = document.querySelector('df-messenger');
        const micBtn = document.getElementById('voice-trigger-btn');
        const statusDiv = document.getElementById('status-indicator');

        // Helper: Ensure Chat is Open
        function ensureChatOpen() {
            // Force the expand attribute
            dfMessenger.setAttribute('expand', 'true');
        }

        // Helper: Update Status Text
        function setStatus(text, show = true) {
            statusDiv.innerText = text;
            statusDiv.style.display = show ? 'block' : 'none';
        }

        // --- 1. RESPONSE HANDLING (BOT SPEAKS) ---
        window.addEventListener('df-response-received', (event) => {
            console.log("Response received from Agent.");
            const botText = event.detail.response.queryResult.fulfillmentText;
            if (botText) speakText(botText);
        });

        function speakText(text) {
            // Stop mic strictly
            try { recognition.stop(); } catch(e) {}
            window.speechSynthesis.cancel();

            setStatus("Alice is speaking...");

            const utterance = new SpeechSynthesisUtterance(text);
            
            // Restart Mic logic
            utterance.onend = () => {
                 if (micBtn.classList.contains('recording')) {
                     console.log("Bot finished. Restarting mic...");
                     try {
                         recognition.start();
                         setStatus("Listening...");
                     } catch (e) { console.log("Mic start error (safe to ignore):", e); }
                 }
            };
            window.speechSynthesis.speak(utterance);
        }


        // --- 2. VOICE RECOGNITION SETUP ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (!SpeechRecognition) {
            console.error("Web Speech API not supported");
            micBtn.style.display = "none";
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.lang = 'en-US';
        recognition.interimResults = false;

        // --- CLICK HANDLER ---
        micBtn.addEventListener('click', () => {
            if (micBtn.classList.contains('recording')) {
                // STOP
                micBtn.classList.remove('recording');
                recognition.stop();
                window.speechSynthesis.cancel();
                setStatus("", false);
            } else {
                // START
                micBtn.classList.add('recording');
                ensureChatOpen(); // Open window immediately
                recognition.start();
                setStatus("Listening...");
            }
        });

        // --- SPEECH EVENTS ---
        recognition.onstart = () => { console.log("Mic started."); };
        
        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            console.log("Captured Audio: ", transcript);

            if (transcript) {
                setStatus("Thinking...");
                
                // 1. Force visual display (User Bubble)
                // We access the Shadow DOM or public API depending on version availability
                // The public API is safest:
                dfMessenger.renderCustomText(transcript, true);

                // 2. Send to Bot
                // Direct call without timeout to ensure it fires
                dfMessenger.sendRequestQuery(transcript);
            }
        };

        recognition.onerror = (event) => {
            console.error("Speech Error:", event.error);
            if (event.error === 'no-speech') {
                if (micBtn.classList.contains('recording')) {
                    try { recognition.start(); } catch(e) {}
                }
            } else {
                micBtn.classList.remove('recording');
                setStatus("Error. Retry.");
            }
        };
    }
  </script>
</body>
</html>