<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Alice Agent (Wake Word: "Alice")</title>

  <link rel="stylesheet" href="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/themes/df-messenger-default.css">
  <style>
    /* Widget Styling */
    df-messenger {
      z-index: 999;
      position: fixed;
      --df-messenger-font-color: #000;
      --df-messenger-font-family: Google Sans;
      --df-messenger-chat-background: #f3f6fc;
      --df-messenger-message-user-background: #d3e3fd;
      --df-messenger-message-bot-background: #fff;
      bottom: 16px;
      right: 16px;
    }

    /* Microphone Button */
    #voice-trigger-btn {
      position: fixed;
      bottom: 20px;       
      right: 90px;        
      z-index: 1000;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      border: none;
      background-color: #4285F4; /* Default Blue */
      color: white;
      font-size: 24px;
      cursor: pointer;
      box-shadow: 0 4px 8px rgba(0,0,0,0.2);
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
      outline: none;
    }

    #voice-trigger-btn:hover {
      transform: scale(1.1);
    }

    /* STATE: ARMED (Listening for "Alice") - Green Pulse */
    #voice-trigger-btn.armed {
      background-color: #34A853; 
      animation: pulse-green 2s infinite;
    }

    /* STATE: PROCESSING (Heard "Alice", sending data) - Red Pulse */
    #voice-trigger-btn.processing {
      background-color: #EA4335;
      animation: pulse-red 0.5s infinite;
    }

    /* Mute Button */
    #mute-btn {
      position: fixed;
      bottom: 25px;       
      right: 150px;       
      z-index: 1000;
      width: 40px;   
      height: 40px;
      border-radius: 50%;
      border: none;
      background-color: #f1f3f4;
      color: #5f6368;
      font-size: 20px;
      cursor: pointer;
      box-shadow: 0 2px 6px rgba(0,0,0,0.2);
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.2s ease;
      outline: none;
    }

    #mute-btn:hover {
      background-color: #e8eaed;
      transform: scale(1.1);
    }
    
    #mute-btn.muted {
      background-color: #fce8e6;
      color: #d93025;
    }

    @keyframes pulse-green {
      0% { box-shadow: 0 0 0 0 rgba(52, 168, 83, 0.7); }
      70% { box-shadow: 0 0 0 10px rgba(52, 168, 83, 0); }
      100% { box-shadow: 0 0 0 0 rgba(52, 168, 83, 0); }
    }

    @keyframes pulse-red {
      0% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0.7); }
      70% { box-shadow: 0 0 0 10px rgba(234, 67, 53, 0); }
      100% { box-shadow: 0 0 0 0 rgba(234, 67, 53, 0); }
    }
  </style>
</head>
<body>

  <script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
   
  <df-messenger
    location="us"
    project-id="vz-nonit-np-k25v-dev-aliceg-0"
    agent-id="3adf7da3-c967-48ee-b295-9a67c9b090fe"
    language-code="en"
    max-query-length="-1">
    <df-messenger-chat-bubble
      chat-title="alice3-duplicate"
      chat-title-icon="https://storage.cloud.google.com/alice-avatars/ALICE TT&I.png">
    </df-messenger-chat-bubble>
  </df-messenger>

  <button id="mute-btn" title="Toggle Sound Response">üîä</button>
  <button id="voice-trigger-btn" title="Click to Arm 'Alice'">üéôÔ∏è</button>

  <script>
    const dfMessenger = document.querySelector('df-messenger');
    const micBtn = document.getElementById('voice-trigger-btn');
    const muteBtn = document.getElementById('mute-btn');
    
    const WAKE_WORD = "alice";
    let isWakeWordActive = false; // Is the loop running?
    let isMuted = false;
    let audioUnlocked = false; 
    let availableVoices = [];

    window.speechSynthesis.onvoiceschanged = () => {
        availableVoices = window.speechSynthesis.getVoices();
    };

    // ---------------------------------------------------------
    // 1. RESPONSE HANDLER
    // ---------------------------------------------------------
    window.addEventListener('df-response-received', (event) => {
        let botText = "";

        if (event.detail.messages && event.detail.messages.length > 0) {
            const msg = event.detail.messages.find(m => m.type === 'text');
            if (msg && msg.text) botText = msg.text;
        }
        
        if (!botText && event.detail.raw && event.detail.raw.queryResult) {
            const qr = event.detail.raw.queryResult;
            if (qr.responseMessages) {
                const textMsg = qr.responseMessages.find(m => m.text);
                if (textMsg && textMsg.text.text.length > 0) {
                    botText = textMsg.text.text[0];
                }
            }
        }

        if (botText && !isMuted) speakText(botText);
    });

    // ---------------------------------------------------------
    // 2. NATURAL VOICE SELECTOR
    // ---------------------------------------------------------
    function speakText(text) {
        window.speechSynthesis.cancel();
        const utterance = new SpeechSynthesisUtterance(text);
        
        if (availableVoices.length === 0) {
            availableVoices = window.speechSynthesis.getVoices();
        }

        let selectedVoice = null;
        selectedVoice = availableVoices.find(v => v.name.includes("Natural") && v.name.includes("English"));
        if (!selectedVoice) selectedVoice = availableVoices.find(v => v.name.includes("Google") && v.name.includes("English"));
        if (!selectedVoice) selectedVoice = availableVoices.find(v => v.name.includes("Zira"));
        if (!selectedVoice) selectedVoice = availableVoices.find(v => v.lang.includes('en-US'));

        if (selectedVoice) utterance.voice = selectedVoice;
        utterance.rate = 1.0; 
        utterance.pitch = 1.0; 

        window.speechSynthesis.speak(utterance);
    }

    // ---------------------------------------------------------
    // 3. WAKE WORD ENGINE
    // ---------------------------------------------------------
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      // Continuous is KEY for wake words
      recognition.continuous = true;
      recognition.interimResults = false; 
      recognition.lang = 'en-US';

      // --- CLICK HANDLER (Toggle Arm/Disarm) ---
      micBtn.addEventListener('click', () => {
        // Unlock Audio Context
        if (!audioUnlocked) {
            const utterance = new SpeechSynthesisUtterance('');
            window.speechSynthesis.speak(utterance);
            audioUnlocked = true;
        }

        if (isWakeWordActive) {
            // STOP Listening
            isWakeWordActive = false;
            recognition.stop();
            micBtn.classList.remove('armed', 'processing');
            micBtn.style.backgroundColor = "#4285F4"; // Back to Blue
            console.log("üõë Wake Word Deactivated");
        } else {
            // START Listening Loop
            isWakeWordActive = true;
            try {
                recognition.start();
                micBtn.classList.add('armed'); // Pulse Green
                console.log("üü¢ Armed: Listening for 'Alice'...");
            } catch (e) {
                console.warn("Already started", e);
            }
        }
      });

      // --- RESULT HANDLER ---
      recognition.onresult = (event) => {
        // Get the latest result
        const lastIndex = event.results.length - 1;
        const transcript = event.results[lastIndex][0].transcript;
        const lowerText = transcript.toLowerCase().trim();

        console.log("Heard:", lowerText);

        // CHECK FOR WAKE WORD
        if (lowerText.includes(WAKE_WORD)) {
            console.log("‚ö° Wake Word Detected!");
            
            // Visual Cue
            micBtn.classList.remove('armed');
            micBtn.classList.add('processing'); // Red Pulse

            // Extract the command (remove "alice" from the start)
            // e.g. "hey alice tell me a joke" -> "tell me a joke"
            const parts = lowerText.split(WAKE_WORD);
            // We take the last part in case they said "alice alice stop"
            const command = parts[parts.length - 1].trim();

            if (command.length > 0) {
                console.log("Sending Command:", command);
                dfMessenger.renderCustomText(command, true);
                dfMessenger.setAttribute('expand', 'true');
                dfMessenger.sendRequest("query", command);
            } else {
                console.log("Wake word heard, but no command followed.");
            }

            // Return to Green (Armed) state after 2 seconds
            setTimeout(() => {
                if(isWakeWordActive) {
                    micBtn.classList.remove('processing');
                    micBtn.classList.add('armed');
                }
            }, 2000);
        }
      };

      // --- AUTO-RESTART LOOP ---
      recognition.onend = () => {
        if (isWakeWordActive) {
            console.log("üîÑ Loop restarting...");
            // Browsers often stop listening after silence. We force it back on.
            try {
                recognition.start();
            } catch(e) {
                // If it fails immediately, wait a split second
                setTimeout(() => recognition.start(), 500);
            }
        } else {
            micBtn.classList.remove('armed', 'processing');
        }
      };

      recognition.onerror = (event) => {
        console.error("Speech Error:", event.error);
        // "no-speech" errors are common in loops; we just ignore and let onend restart it.
      };

    } else {
        console.error("Web Speech API not supported");
        micBtn.style.display = "none";
    }

    // ---------------------------------------------------------
    // 4. MUTE TOGGLE
    // ---------------------------------------------------------
    muteBtn.addEventListener('click', () => {
        isMuted = !isMuted;
        muteBtn.textContent = isMuted ? "üîá" : "üîä";
        muteBtn.classList.toggle('muted', isMuted);
        if (isMuted) window.speechSynthesis.cancel();
    });

  </script>
</body>
</html>




